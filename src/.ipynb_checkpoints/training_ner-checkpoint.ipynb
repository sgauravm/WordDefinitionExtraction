{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess as pp\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW,BartTokenizerFast, BartForSequenceClassification\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score,accuracy_score,confusion_matrix, precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizerFast, RobertaForTokenClassification,get_cosine_schedule_with_warmup\n",
    "from transformers import BertForTokenClassification,BertModel\n",
    "from functools import reduce\n",
    "import spacy\n",
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out_logits,labels):\n",
    "    if type(out_logits) != torch.Tensor:\n",
    "        pred = [val for vals in out_logits for val in vals]\n",
    "        target = [val for vals in labels for val in vals]\n",
    "        return np.mean(np.array(pred)==np.array(target))\n",
    "    else:\n",
    "        pred = out_logits.argmax(dim=2)\n",
    "        return torch.mean((pred[labels!=-100] == labels[labels!=-100]).float()).item()\n",
    "\n",
    "def val_params(model,val_loader):\n",
    "    temp = model.eval()\n",
    "    num_batches = 0\n",
    "    loss_sum = 0\n",
    "    accuracy_sum =0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward(input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        #loss = criterion(outputs.logits.view(-1,2),labels.view(-1))\n",
    "        loss = outputs[0]\n",
    "        if len(outputs)!=1:\n",
    "            pred = outputs[1].argmax(dim=2)\n",
    "            y_pred = y_pred + pred[labels!=-100].view(-1).tolist()\n",
    "            y_true = y_true + labels[labels!=-100].view(-1).tolist()\n",
    "        else:\n",
    "            labels = list(map(lambda label,mask:label[mask==1].tolist(),labels,attention_mask))\n",
    "            pred = model.decode(input_ids, attention_mask=attention_mask)\n",
    "            pred = [val for vals in pred for val in vals]\n",
    "            labels = [val for vals in labels for val in vals]\n",
    "            y_pred = y_pred + pred\n",
    "            y_true = y_true + labels\n",
    "            \n",
    "        loss_sum += loss.item()\n",
    "        num_batches +=1\n",
    "    f1_micro = f1_score(np.array(y_true).reshape(-1),np.array(y_pred).reshape(-1),average='micro')\n",
    "    f1_macro = f1_score(np.array(y_true).reshape(-1),np.array(y_pred).reshape(-1),average='macro')\n",
    "    acc = accuracy_score(np.array(y_true).reshape(-1),np.array(y_pred).reshape(-1))\n",
    "    return loss_sum/num_batches,acc,f1_micro,f1_macro\n",
    "\n",
    "def get_ytyp(model,val_loader):\n",
    "    temp = model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward(input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        #loss = criterion(outputs.logits.view(-1,2),labels.view(-1))\n",
    "        loss = outputs[0]\n",
    "        pred = outputs[1].argmax(dim=2)\n",
    "        \n",
    "        y_pred = y_pred + pred[labels!=-100].view(-1).tolist()\n",
    "        y_true = y_true + labels[labels!=-100].view(-1).tolist()\n",
    "        \n",
    "    return y_pred,y_true\n",
    "\n",
    "def get_model_out(model,val_loader):\n",
    "    temp = model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward(input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        #loss = criterion(outputs.logits.view(-1,2),labels.view(-1))\n",
    "        loss = outputs[0]\n",
    "        pred = outputs[1].argmax(dim=2)\n",
    "        \n",
    "        \n",
    "        y_pred = y_pred + pred[labels!=-100].view(-1).tolist()\n",
    "        y_true = y_true + labels[labels!=-100].view(-1).tolist()\n",
    "        loss_sum += loss.item()\n",
    "        accuracy_sum += accuracy(outputs[1],labels)\n",
    "        num_batches +=1\n",
    "    cm = confusion_matrix(np.array(y_true).reshape(-1),np.array(y_pred).reshape(-1))\n",
    "    return cm\n",
    "\n",
    "\n",
    "class DefinitionERDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "    \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues,\n",
    "                         figsize = (10,10)):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm =np.round(cm,2)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def get_dataloader(dir_path,tokenizer, batch_size=32):\n",
    "    x,y,tags = pp.get_data_slt(dir_path)\n",
    "    encodings = tokenizer(x,is_split_into_words=True,  padding=True, truncation=True,return_tensors=\"pt\")\n",
    "    dataset = DefinitionDataset(encodings,y)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return data_loader\n",
    "\n",
    "def get_encodings(text,tags,tokenizer):\n",
    "    encodings  = tokenizer(text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True,return_tensors='pt')\n",
    "    seq_len = encodings.input_ids.shape[1]\n",
    "    labels = [[lab2id[tok] for tok in seq] for seq in tags]\n",
    "    enc_labels = []\n",
    "    input_ids = []\n",
    "    out_enc = {}\n",
    "    for off_map_seq,lab_seq in zip(encodings.offset_mapping,labels):\n",
    "        tags = np.ones(seq_len,dtype=int) * -100\n",
    "        \n",
    "        \n",
    "        tags[(off_map_seq[:,0] == 0) & (off_map_seq[:,1] != 0)]= lab_seq\n",
    "        \n",
    "        enc_labels.append(tags)\n",
    "        \n",
    "\n",
    "    encodings['labels'] = torch.tensor(enc_labels)  \n",
    "    \n",
    "    return encodings\n",
    "\n",
    "\n",
    "\n",
    "def get_encodings_crf(text,tags,tokenizer):\n",
    "    encodings  = tokenizer(text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True,return_tensors='pt')\n",
    "    seq_len = encodings.input_ids.shape[1]\n",
    "    labels = [[lab2id[tok] for tok in seq] for seq in tags]\n",
    "    enc_labels = []\n",
    "    input_ids = []\n",
    "    out_enc = {}\n",
    "    for off_map_seq,lab_seq,in_id in zip(encodings.offset_mapping,labels,encodings.input_ids):\n",
    "        inp_id = [0]*seq_len\n",
    "        tags = [lab2id[' O']]*seq_len\n",
    "        in_id_nopad = in_id[off_map_seq[:,0]==0][in_id[off_map_seq[:,0]==0]!=0].tolist()\n",
    "        inp_id[:len(in_id_nopad)]=in_id_nopad\n",
    "        tags[1:(len(lab_seq)+1)]= lab_seq\n",
    "        \n",
    "        input_ids.append(inp_id)\n",
    "        enc_labels.append(tags)\n",
    "        \n",
    "\n",
    "    out_enc['labels'] = torch.tensor(enc_labels) \n",
    "    out_enc['input_ids'] = torch.tensor(input_ids) \n",
    "    out_enc['attention_mask']=torch.logical_and(out_enc['input_ids']!=0 , out_enc['input_ids']!=102).type(torch.ByteTensor)\n",
    "    \n",
    "    return out_enc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb  7 19:31:41 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    27W / 250W |      8MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-PCIE...  On   | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    23W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-PCIE...  On   | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    24W / 250W |      8MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-PCIE...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    25W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-PCIE...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    25W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1631      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      1631      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1631      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      1631      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A      1631      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A      1631      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    6   N/A  N/A      1631      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      1631      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
      "root        1613  3.0  0.0      0     0 ?        R    Jan29 414:53 [nv_queue]\n",
      "root        1977  3.8  0.0      0     0 ?        R    Jan29 520:53 [nv_queue]\n",
      "gsinha1   576946 44.0  0.0  11716  3604 pts/16   Rs+  19:31   0:00 ps aux grep 3\n"
     ]
    }
   ],
   "source": [
    "!ps aux grep 3165672"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2], device='cuda:2')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../data/deft_files/train/'\n",
    "dir_path_val = '../data/deft_files/dev/'\n",
    "model_name = 'bert-large-cased'  #  \"facebook/bart-large\" 'roberta-base'\n",
    "Model = BertForTokenClassification\n",
    "ModelTokenizer = BertTokenizerFast #BertTokenizerFast\n",
    "path_to_save = \"../model/berta_ner/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train,_,tags_train = pp.get_data_slt(dir_path)\n",
    "texts_val,_,tags_val = pp.get_data_slt(dir_path_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = {}\n",
    "for seq in tags_train:\n",
    "    for tok in seq:\n",
    "        if tok not in unique_tags.keys():\n",
    "            unique_tags[tok] = 1\n",
    "        else:\n",
    "            unique_tags[tok] += 1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2lab = sorted(list(unique_tags.keys()))\n",
    "classes = id2lab.copy()\n",
    "id2lab = {val:key for val,key in enumerate(id2lab)}\n",
    "id2lab[-100] = 'other'\n",
    "lab2id = {key:val for val,key in id2lab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' B-Alias-Term': 0,\n",
       " ' B-Alias-Term-frag': 1,\n",
       " ' B-Definition': 2,\n",
       " ' B-Definition-frag': 3,\n",
       " ' B-Qualifier': 4,\n",
       " ' B-Referential-Definition': 5,\n",
       " ' B-Referential-Term': 6,\n",
       " ' B-Secondary-Definition': 7,\n",
       " ' B-Term': 8,\n",
       " ' B-Term-frag': 9,\n",
       " ' I-Alias-Term': 10,\n",
       " ' I-Definition': 11,\n",
       " ' I-Definition-frag': 12,\n",
       " ' I-Qualifier': 13,\n",
       " ' I-Referential-Definition': 14,\n",
       " ' I-Referential-Term': 15,\n",
       " ' I-Secondary-Definition': 16,\n",
       " ' I-Term': 17,\n",
       " ' I-Term-frag': 18,\n",
       " ' O': 19,\n",
       " 'other': -100}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1]*len(id2lab)\n",
    "for lab,num in unique_tags.items():\n",
    "    weights[lab2id[lab]] = 1000/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor(weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3774e+00, 3.3333e+02, 1.6496e-01, 1.1765e+01, 6.1728e+00, 3.2468e+00,\n",
       "        7.1429e+00, 2.0877e+00, 1.5126e-01, 1.2500e+02, 1.1628e+00, 1.1476e-02,\n",
       "        1.0471e+00, 9.5694e-01, 1.5129e+00, 8.6207e+00, 1.2155e-01, 1.0470e-01,\n",
       "        3.3333e+02, 2.8978e-03, 1.0000e+00], device='cuda:2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ModelTokenizer.from_pretrained(model_name,add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = get_encodings(texts_train,tags_train,tokenizer)\n",
    "val_encodings = get_encodings(texts_val,tags_val,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systems</td>\n",
       "      <td>B-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biology</td>\n",
       "      <td>I-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>B-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>study</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>whole</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>biological</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>systems</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>genome</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>##s</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pro</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>##te</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>##ome</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>##s</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>)</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>based</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>on</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>interactions</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>within</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>system</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tokens          label\n",
       "0          [CLS]          other\n",
       "1        Systems         B-Term\n",
       "2        biology         I-Term\n",
       "3             is              O\n",
       "4            the   B-Definition\n",
       "5          study   I-Definition\n",
       "6             of   I-Definition\n",
       "7          whole   I-Definition\n",
       "8     biological   I-Definition\n",
       "9        systems   I-Definition\n",
       "10             (   I-Definition\n",
       "11        genome   I-Definition\n",
       "12           ##s          other\n",
       "13           and   I-Definition\n",
       "14           pro   I-Definition\n",
       "15          ##te          other\n",
       "16         ##ome          other\n",
       "17           ##s          other\n",
       "18             )   I-Definition\n",
       "19         based   I-Definition\n",
       "20            on   I-Definition\n",
       "21  interactions   I-Definition\n",
       "22        within   I-Definition\n",
       "23           the   I-Definition\n",
       "24        system   I-Definition\n",
       "25             .              O\n",
       "26         [SEP]          other\n",
       "27         [PAD]          other\n",
       "28         [PAD]          other\n",
       "29         [PAD]          other\n",
       "30         [PAD]          other\n",
       "31         [PAD]          other\n",
       "32         [PAD]          other\n",
       "33         [PAD]          other\n",
       "34         [PAD]          other\n",
       "35         [PAD]          other\n",
       "36         [PAD]          other\n",
       "37         [PAD]          other\n",
       "38         [PAD]          other\n",
       "39         [PAD]          other\n",
       "40         [PAD]          other\n",
       "41         [PAD]          other\n",
       "42         [PAD]          other\n",
       "43         [PAD]          other\n",
       "44         [PAD]          other\n",
       "45         [PAD]          other\n",
       "46         [PAD]          other\n",
       "47         [PAD]          other\n",
       "48         [PAD]          other\n",
       "49         [PAD]          other"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=79\n",
    "df = pd.DataFrame({\n",
    "    'tokens':tokenizer.convert_ids_to_tokens(val_encodings['input_ids'][i].tolist()),\n",
    "    'label':list(map(lambda x: id2lab[x],val_encodings['labels'][i].tolist()))\n",
    "})\n",
    "\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DefinitionERDataset(train_encodings)\n",
    "val_dataset = DefinitionERDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefinitionExtraction(nn.Module):\n",
    "    def __init__(self,num_labels):\n",
    "        super(DefinitionExtraction, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-large-cased')\n",
    "        self.dense = nn.Linear(1024,1024)\n",
    "        self.classification = nn.Linear(1024,num_labels)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.crf = CRF(num_labels,batch_first=True)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self,input_ids,attention_mask=None,labels=None):\n",
    "        x = self.bert(input_ids.long())\n",
    "        x = self.tanh(self.dense(x.last_hidden_state))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.classification(x)\n",
    "        loss = self.crf.forward(logits,labels,attention_mask)\n",
    "        return [loss]\n",
    "    \n",
    "    def decode(self,input_ids,attention_mask=None):\n",
    "        x = self.bert(input_ids.long())\n",
    "        x = self.tanh(self.dense(x.last_hidden_state))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.classification(x)\n",
    "        output = self.crf.decode(logits,attention_mask)\n",
    "        return output\n",
    "    \n",
    "    def call(self,input_ids,attention_mask=None,labels=None):\n",
    "        return self.forward(input_ids,attention_mask,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = DefinitionExtraction(len(id2lab)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Model.from_pretrained(model_name,num_labels=len(id2lab)).to(device)\n",
    "#model = nn.DataParallel(model,device_ids=[0,1,3],output_device=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=12\n",
    "optim = AdamW(model.parameters(), lr=1e-5)\n",
    "sched = get_cosine_schedule_with_warmup(optim,\n",
    "                                        num_warmup_steps=100,\n",
    "                                        num_training_steps=(len(tags_train)/BATCH_SIZE)*EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 0.694759, Train accuracy: 0.797223: 100%|██████████| 756/756 [12:58<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.424543, Val accuracy: 0.865361, Val f1-micro: 0.865361, Val f1-macro: 0.223196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.393899, Train accuracy: 0.873018: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.401640, Val accuracy: 0.863439, Val f1-micro: 0.863439, Val f1-macro: 0.331345"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.285852, Train accuracy: 0.908199: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.416888, Val accuracy: 0.866524, Val f1-micro: 0.866524, Val f1-macro: 0.355822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.200731, Train accuracy: 0.933132: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.511185, Val accuracy: 0.870725, Val f1-micro: 0.870725, Val f1-macro: 0.329760"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.136093, Train accuracy: 0.950112: 100%|██████████| 756/756 [12:45<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.572076, Val accuracy: 0.866166, Val f1-micro: 0.866166, Val f1-macro: 0.335091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 0.103269, Train accuracy: 0.959592: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.637583, Val accuracy: 0.860489, Val f1-micro: 0.860489, Val f1-macro: 0.328766"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train loss: 0.081992, Train accuracy: 0.963605: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.685772, Val accuracy: 0.863171, Val f1-micro: 0.863171, Val f1-macro: 0.335381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train loss: 0.068182, Train accuracy: 0.966254: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.755975, Val accuracy: 0.865406, Val f1-micro: 0.865406, Val f1-macro: 0.335497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Train loss: 0.058626, Train accuracy: 0.968941: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.756920, Val accuracy: 0.862501, Val f1-micro: 0.862501, Val f1-macro: 0.335066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Train loss: 0.052772, Train accuracy: 0.970506: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.822273, Val accuracy: 0.864914, Val f1-micro: 0.864914, Val f1-macro: 0.317651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.048222, Train accuracy: 0.972710: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.826628, Val accuracy: 0.864601, Val f1-micro: 0.864601, Val f1-macro: 0.318961"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 0.046114, Train accuracy: 0.974718: 100%|██████████| 756/756 [12:46<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.856139, Val accuracy: 0.865183, Val f1-micro: 0.865183, Val f1-macro: 0.320008"
     ]
    }
   ],
   "source": [
    "prev_val_acc = -1\n",
    "temp = model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_sum = 0\n",
    "    accuracy_sum = 0\n",
    "    num_batch = 0\n",
    "    pbar = tqdm.tqdm(train_loader)\n",
    "    for batch in pbar:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        sched.step()\n",
    "        loss_sum += loss.item()\n",
    "        if len(outputs)==1:\n",
    "            out = model.decode(input_ids, attention_mask=attention_mask)\n",
    "            outputs.append(out)\n",
    "            labels = list(map(lambda label,mask:label[mask==1].tolist(),labels,attention_mask))\n",
    "        accuracy_sum += accuracy(outputs[1],labels)\n",
    "        num_batch+=1\n",
    "        pbar.set_description(\"Epoch: %s, Train loss: %f, Train accuracy: %f\"%(epoch,\n",
    "                                                                              loss_sum/num_batch,\n",
    "                                                                              accuracy_sum/num_batch))\n",
    "    val_metric = val_params(model,val_loader)\n",
    "    sys.stdout.write(\"         Val loss: %f, Val accuracy: %f, Val f1-micro: %f, Val f1-macro: %f\"%val_metric)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    #Breaking criteria\n",
    "    if prev_val_acc > val_metric[2]:\n",
    "        pass\n",
    "    \n",
    "    prev_val_acc = val_metric[2]\n",
    "    \n",
    "    #saving model checkpoint\n",
    "    model.save_pretrained(path_to_save+str(epoch))\n",
    "    tokenizer.save_pretrained(path_to_save+str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metric = val_params(model,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251.73746057458825, 0.8533271051849335, 0.8533271051849335, 0.311064348700263)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ModelTokenizer.from_pretrained(path_to_save+str(0))\n",
    "model = Model.from_pretrained(path_to_save+str(0)).to(device)\n",
    "temp = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt,yp = get_ytyp(model,val_loader)\n",
    "yt = [id2lab[idx] for idx in yt]\n",
    "yp = [id2lab[idx] for idx in yp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set(yt+yp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(yt,yp)\n",
    "plot_confusion_matrix(cm,classes,normalize=True,figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nltk.download('punkt')\n",
    "text = \"SWOT stands for Strengths, Weaknesses, Opportunities, and Threats, and so a SWOT Analysis is a technique for assessing these four aspects of your business.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_individual_predictions(i,text=None):\n",
    "    if text is None:\n",
    "        custom = False\n",
    "    else:\n",
    "        cutome=True\n",
    "\n",
    "    split_text = texts_val[i]\n",
    "    tags = tags_val[i]\n",
    "    if custom:\n",
    "        split_text = word_tokenize(text)\n",
    "        tags = [' O']*len(split_text)\n",
    "    enc = get_encodings([split_text],[tags],tokenizer)\n",
    "    lab = enc.labels[0]\n",
    "    with torch.no_grad():\n",
    "        output = model(enc.input_ids.to(device),enc.attention_mask.to(device))\n",
    "    pred_out = output[0].argmax(dim=2)[0]\n",
    "    pred_out=pred_out[lab!=-100]\n",
    "    lab = lab[lab!=-100]\n",
    "    lab = [id2lab[idx] for idx in lab.tolist()]\n",
    "    pred_out = [id2lab[idx] for idx in pred_out.tolist()]\n",
    "\n",
    "    res = pd.DataFrame({\n",
    "        'texts':split_text,\n",
    "         'targ': lab,\n",
    "        'pred':pred_out\n",
    "\n",
    "    })\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>targ</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1869</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stanton</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anthony</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>formed</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>B-Term</td>\n",
       "      <td>B-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>National</td>\n",
       "      <td>I-Term</td>\n",
       "      <td>I-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Woman</td>\n",
       "      <td>I-Term</td>\n",
       "      <td>I-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Suffrage</td>\n",
       "      <td>I-Term</td>\n",
       "      <td>I-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Association</td>\n",
       "      <td>I-Term</td>\n",
       "      <td>I-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NWSA</td>\n",
       "      <td>B-Alias-Term</td>\n",
       "      <td>B-Alias-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>)</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>which</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>demanded</td>\n",
       "      <td>B-Definition</td>\n",
       "      <td>B-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>that</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Constitution</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>be</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>amended</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>to</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>grant</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>right</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>to</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vote</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>to</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>all</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>women</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           texts           targ           pred\n",
       "0             In              O              O\n",
       "1           1869              O              O\n",
       "2              ,              O              O\n",
       "3        Stanton              O              O\n",
       "4            and              O              O\n",
       "5        Anthony              O              O\n",
       "6         formed              O              O\n",
       "7            the         B-Term         B-Term\n",
       "8       National         I-Term         I-Term\n",
       "9          Woman         I-Term         I-Term\n",
       "10      Suffrage         I-Term         I-Term\n",
       "11   Association         I-Term         I-Term\n",
       "12             (              O              O\n",
       "13          NWSA   B-Alias-Term   B-Alias-Term\n",
       "14             )              O              O\n",
       "15             ,              O              O\n",
       "16         which              O              O\n",
       "17      demanded   B-Definition   B-Definition\n",
       "18          that   I-Definition   I-Definition\n",
       "19           the   I-Definition   I-Definition\n",
       "20  Constitution   I-Definition   I-Definition\n",
       "21            be   I-Definition   I-Definition\n",
       "22       amended   I-Definition   I-Definition\n",
       "23            to   I-Definition   I-Definition\n",
       "24         grant   I-Definition   I-Definition\n",
       "25           the   I-Definition   I-Definition\n",
       "26         right   I-Definition   I-Definition\n",
       "27            to   I-Definition   I-Definition\n",
       "28          vote   I-Definition   I-Definition\n",
       "29            to   I-Definition   I-Definition\n",
       "30           all   I-Definition   I-Definition\n",
       "31         women   I-Definition   I-Definition\n",
       "32             .              O              O"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = get_individual_predictions(30)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>targ</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inductive</td>\n",
       "      <td>B-Term</td>\n",
       "      <td>B-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reasoning</td>\n",
       "      <td>I-Term</td>\n",
       "      <td>I-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>B-Definition</td>\n",
       "      <td>B-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>form</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logical</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thinking</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>that</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>uses</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>related</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>observations</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>to</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>arrive</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>at</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>general</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>conclusion</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           texts           targ           pred\n",
       "0      Inductive         B-Term         B-Term\n",
       "1      reasoning         I-Term         I-Term\n",
       "2             is              O              O\n",
       "3              a   B-Definition   B-Definition\n",
       "4           form   I-Definition   I-Definition\n",
       "5             of   I-Definition   I-Definition\n",
       "6        logical   I-Definition   I-Definition\n",
       "7       thinking   I-Definition   I-Definition\n",
       "8           that   I-Definition   I-Definition\n",
       "9           uses   I-Definition   I-Definition\n",
       "10       related   I-Definition   I-Definition\n",
       "11  observations   I-Definition   I-Definition\n",
       "12            to   I-Definition   I-Definition\n",
       "13        arrive   I-Definition   I-Definition\n",
       "14            at   I-Definition   I-Definition\n",
       "15             a   I-Definition   I-Definition\n",
       "16       general   I-Definition   I-Definition\n",
       "17    conclusion   I-Definition   I-Definition\n",
       "18             .              O              O"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = get_individual_predictions(1)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>targ</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United</td>\n",
       "      <td>B-Term</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>States</td>\n",
       "      <td>I-Term</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v.</td>\n",
       "      <td>I-Term</td>\n",
       "      <td>I-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Miller</td>\n",
       "      <td>I-Term</td>\n",
       "      <td>I-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>B-Definition</td>\n",
       "      <td>B-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Supreme</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Court</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>upheld</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1934</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>National</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Firearms</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Act</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>’s</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>prohibition</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>of</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sawed</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>off</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>shotguns</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>,</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>largely</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>on</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>basis</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>that</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>possession</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>of</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>such</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>a</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gun</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>was</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>not</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>related</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>to</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>the</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>goal</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>of</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>promoting</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>a</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>“</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>well</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>regulated</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>militia</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>I-Definition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>.</td>\n",
       "      <td>I-Definition</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          texts           targ           pred\n",
       "0            In              O              O\n",
       "1        United         B-Term              O\n",
       "2        States         I-Term              O\n",
       "3            v.         I-Term         I-Term\n",
       "4        Miller         I-Term         I-Term\n",
       "5             ,              O              O\n",
       "6           the   B-Definition   B-Definition\n",
       "7       Supreme   I-Definition              O\n",
       "8         Court   I-Definition              O\n",
       "9        upheld   I-Definition   I-Definition\n",
       "10          the   I-Definition   I-Definition\n",
       "11         1934   I-Definition   I-Definition\n",
       "12     National   I-Definition              O\n",
       "13     Firearms   I-Definition         I-Term\n",
       "14          Act   I-Definition              O\n",
       "15           ’s   I-Definition   I-Definition\n",
       "16  prohibition   I-Definition   I-Definition\n",
       "17           of   I-Definition   I-Definition\n",
       "18        sawed   I-Definition   I-Definition\n",
       "19            -   I-Definition   I-Definition\n",
       "20          off   I-Definition   I-Definition\n",
       "21     shotguns   I-Definition   I-Definition\n",
       "22            ,   I-Definition   I-Definition\n",
       "23      largely   I-Definition   I-Definition\n",
       "24           on   I-Definition   I-Definition\n",
       "25          the   I-Definition   I-Definition\n",
       "26        basis   I-Definition   I-Definition\n",
       "27         that   I-Definition   I-Definition\n",
       "28   possession   I-Definition   I-Definition\n",
       "29           of   I-Definition   I-Definition\n",
       "30         such   I-Definition   I-Definition\n",
       "31            a   I-Definition   I-Definition\n",
       "32          gun   I-Definition   I-Definition\n",
       "33          was   I-Definition   I-Definition\n",
       "34          not   I-Definition   I-Definition\n",
       "35      related   I-Definition              O\n",
       "36           to   I-Definition              O\n",
       "37          the   I-Definition   I-Definition\n",
       "38         goal   I-Definition   I-Definition\n",
       "39           of   I-Definition   I-Definition\n",
       "40    promoting   I-Definition              O\n",
       "41            a   I-Definition   I-Definition\n",
       "42            “   I-Definition              O\n",
       "43         well   I-Definition   I-Definition\n",
       "44    regulated   I-Definition   I-Definition\n",
       "45      militia   I-Definition   I-Definition\n",
       "46            .   I-Definition              O"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = get_individual_predictions(5)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>targ</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reexamination</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>past</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cases</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DNA</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>evidence</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>has</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>revealed</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dozens</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>which</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>people</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>were</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wrongfully</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>executed</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            texts targ pred\n",
       "0             The    O    O\n",
       "1   reexamination    O    O\n",
       "2              of    O    O\n",
       "3            past    O    O\n",
       "4           cases    O    O\n",
       "5         through    O    O\n",
       "6             DNA    O    O\n",
       "7        evidence    O    O\n",
       "8             has    O    O\n",
       "9        revealed    O    O\n",
       "10         dozens    O    O\n",
       "11             in    O    O\n",
       "12          which    O    O\n",
       "13         people    O    O\n",
       "14           were    O    O\n",
       "15     wrongfully    O    O\n",
       "16       executed    O    O\n",
       "17              .    O    O"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = get_individual_predictions(9)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
