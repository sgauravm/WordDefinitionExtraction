{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess as pp\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW,BartTokenizerFast, BartForSequenceClassification\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score,accuracy_score,confusion_matrix, precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 10 09:02:13 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-PCIE...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    26W / 250W |      8MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-PCIE...  On   | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-PCIE...  On   | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    23W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-PCIE...  On   | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    23W / 250W |      8MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-PCIE...  On   | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    25W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-PCIE...  On   | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   31C    P0    24W / 250W |      8MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    4   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    5   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    6   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    7   N/A  N/A      1698      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out_logits,labels):\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    predicted = out_logits.detach().cpu().numpy()\n",
    "    predicted = np.argmax(predicted,axis=1).reshape(labels.shape)\n",
    "    return np.mean(labels == predicted)\n",
    "\n",
    "def val_params(model,val_loader):\n",
    "    temp = model.eval()\n",
    "    num_batches = 0\n",
    "    loss_sum = 0\n",
    "    accuracy_sum =0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.forward(input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        loss = criterion(outputs.logits.view(-1,2),labels.view(-1))\n",
    "        y_pred = y_pred + torch.argmax(outputs.logits,axis=1).detach().cpu().tolist()\n",
    "        y_true = y_true + labels.detach().cpu().tolist()\n",
    "        loss_sum += loss.item()\n",
    "        accuracy_sum += accuracy(outputs.logits,labels)\n",
    "        num_batches +=1\n",
    "    return loss_sum/num_batches,accuracy_sum/num_batches,f1_score(y_true,y_pred)\n",
    "\n",
    "class DefinitionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues,\n",
    "                         figsize = (10,10)):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm =np.round(cm,2)\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def get_dataloader(dir_path,tokenizer, batch_size=32):\n",
    "    x,y,tags = pp.get_data_slt(dir_path)\n",
    "    encodings = tokenizer(x,is_split_into_words=True,  padding=True, truncation=True,return_tensors=\"pt\")\n",
    "    dataset = DefinitionDataset(encodings,y)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../data/deft_files/train/'\n",
    "dir_path_val = '../data/deft_files/dev/'\n",
    "model_name =  'roberta-base'\n",
    "#'bert-base-uncased'\n",
    "#\"facebook/bart-large\"\n",
    "Model = RobertaForSequenceClassification\n",
    "ModelTokenizer = RobertaTokenizer\n",
    "path_to_save = \"../model/roberta_cls/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,tags = pp.get_data_slt(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.mean(y_train)\n",
    "weights = [0.2,0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ModelTokenizer.from_pretrained(model_name,add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(x_train,is_split_into_words=True,  padding=True, truncation=True,return_tensors=\"pt\")\n",
    "val_encodings = tokenizer(x_val,is_split_into_words=True,  padding=True, truncation=True,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DefinitionDataset(train_encodings,y_train)\n",
    "val_dataset = DefinitionDataset(val_encodings,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Model.from_pretrained(model_name,num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(model.parameters(), lr=1e-5)\n",
    "weight=torch.tensor(weights,dtype=torch.float).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "mse_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 0.360355, Train accuracy: 0.791181: 100%|██████████| 643/643 [03:43<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.305267, Val accuracy: 0.826115, Val f1: 0.742974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 0.256077, Train accuracy: 0.872440: 100%|██████████| 643/643 [03:40<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.290623, Val accuracy: 0.845669, Val f1: 0.761340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 0.181473, Train accuracy: 0.917217: 100%|██████████| 643/643 [03:42<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.329775, Val accuracy: 0.858096, Val f1: 0.771773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 0.114951, Train accuracy: 0.949618: 100%|██████████| 643/643 [03:43<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.403433, Val accuracy: 0.869518, Val f1: 0.777985"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train loss: 0.077362, Train accuracy: 0.969236: 100%|██████████| 643/643 [03:42<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Val loss: 0.482561, Val accuracy: 0.869243, Val f1: 0.776303"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "prev_val_acc = -1\n",
    "temp = model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_sum = 0\n",
    "    accuracy_sum = 0\n",
    "    num_batch = 0\n",
    "    pbar = tqdm.tqdm(train_loader)\n",
    "    for batch in pbar:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        loss = criterion(outputs.logits.view(-1,2),labels.view(-1))\n",
    "        loss = loss \n",
    "        #loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loss_sum += loss.item()\n",
    "        accuracy_sum += accuracy(outputs.logits,labels)\n",
    "        num_batch+=1\n",
    "        pbar.set_description(\"Epoch: %s, Train loss: %f, Train accuracy: %f\"%(epoch,loss_sum/num_batch,accuracy_sum/num_batch))\n",
    "    \n",
    "    val_metric = val_params(model,val_loader)\n",
    "    sys.stdout.write(\"         Val loss: %f, Val accuracy: %f, Val f1: %f\"%val_metric)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    #Breaking criteria\n",
    "    if prev_val_acc > val_metric[2]:\n",
    "        break\n",
    "    \n",
    "    prev_val_acc = val_metric[2]\n",
    "    \n",
    "    #saving model checkpoint\n",
    "    model.save_pretrained(path_to_save)\n",
    "    tokenizer.save_pretrained(path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_output(data_loader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    t=model.eval()\n",
    "    pbar = tqdm.tqdm(data_loader)\n",
    "    for data in pbar:\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "        labels = data['labels'].to(device)\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "        pred_labels = torch.argmax(output.logits,dim=1).detach().cpu().numpy().tolist()\n",
    "        labels_numpy = labels.detach().cpu().numpy().tolist()\n",
    "        y_true = y_true + labels_numpy\n",
    "        y_pred = y_pred + pred_labels\n",
    "\n",
    "    return y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:03<00:00, 23.77it/s]\n"
     ]
    }
   ],
   "source": [
    "dl = get_dataloader(dir_path_val,tokenizer,batch_size=16)\n",
    "y_true,y_pred = get_model_output(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.888041</td>\n",
       "      <td>0.789137</td>\n",
       "      <td>0.80719</td>\n",
       "      <td>0.771875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy        f1   recall  Precision\n",
       "0  0.888041  0.789137  0.80719   0.771875"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = recall_score(y_true,y_pred)\n",
    "p = precision_score(y_true,y_pred)\n",
    "f1 = f1_score(y_true,y_pred)\n",
    "a = accuracy_score(y_true,y_pred)\n",
    "res = pd.DataFrame({\n",
    "    'accuracy': a,\n",
    "    'f1': f1,\n",
    "    'recall':r,\n",
    "    'Precision':p\n",
    "},index=[0])\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
